{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset 1\n",
    "from sklearn.datasets.samples_generator import make_circles\n",
    "X, y_true = make_circles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-NN graph\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "A = kneighbors_graph(X, n_neighbors = 2, mode = 'connectivity', include_self = False)\n",
    "W = A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.repeat(2, 100)\n",
    "D = np.diag(v = r)\n",
    "L = D - W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, vectors = np.linalg.eig(L)\n",
    "idx = values.argsort()[::1]   \n",
    "values = values[idx]\n",
    "vectors = vectors[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.hstack((vectors[0], vectors[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 1.41421356e-01 -1.36412301e-02 -2.00000000e-01 -1.58776308e-01\n -1.36569418e-01  2.43605566e-02  1.47006507e-02 -1.99923846e-01\n -4.78910351e-04 -1.97368991e-03 -2.31804253e-03 -5.28971955e-02\n -4.40790235e-02  1.99997735e-01 -3.80814592e-02 -1.99947605e-01\n -4.54748820e-03  4.01751188e-03 -1.90588781e-03 -3.52782876e-03\n -1.13976888e-02  1.99827749e-01 -2.83563319e-02  2.29792366e-02\n  2.88672797e-02 -1.97561759e-01 -2.43947759e-04  1.49705631e-04\n  4.46236779e-04 -1.99999778e-01  3.90379861e-03  5.32897732e-03\n  1.99997243e-01 -1.91054853e-02 -1.99943499e-01 -5.18518716e-05\n  4.63526961e-03 -4.05452011e-04 -4.01866251e-03  1.99995116e-01\n -3.10399569e-03  9.21239120e-04  7.73411042e-04  1.99999446e-01\n  1.33712224e-04  2.16675638e-03  2.33762605e-04 -4.80011838e-02\n  1.99734852e-01  2.23692713e-02 -1.23602796e-03 -8.17343794e-04\n -1.18230723e-03 -1.99861054e-01  1.99793167e-01  9.07858851e-03\n  4.61412404e-03  9.82717149e-03  7.85226356e-04 -1.99990840e-01\n -1.03729657e-02  4.98333741e-04  2.03758763e-03  1.70750877e-03\n  2.33416323e-02 -1.99998834e-01  1.33002327e-03 -4.83449705e-02\n -1.99970572e-01 -5.87422855e-04 -6.59410832e-04  1.54054570e-03\n  2.00630218e-03  1.99999877e-01  1.99999983e-01  3.88489025e-03\n  3.21157157e-03  2.40426388e-03 -3.17035155e-03 -1.99611800e-01\n -1.61993217e-03  1.39468166e-02 -2.52454164e-04  1.19369082e-03\n  1.26370101e-03 -1.99998129e-01 -1.88915211e-03  2.00000000e-01\n -5.73729189e-04 -2.74956266e-04  8.30635342e-04 -5.62023297e-03\n -2.00000000e-01 -3.85046271e-03  1.46552560e-03  1.22348547e-02\n -2.00000000e-01 -3.85014150e-05  4.95620924e-04  1.41421356e-01\n  1.41421356e-01 -1.36412301e-02 -8.51558583e-02 -1.29653316e-01\n -1.63061314e-01  8.67795163e-02  1.24599804e-01  1.29560561e-01\n  7.73818608e-02  5.03192358e-03  4.85716991e-02  4.58082681e-02\n  2.72074451e-02 -1.93694831e-01 -7.09894506e-02  4.05723450e-02\n  1.40854294e-01  1.34189042e-01  5.23103366e-02  1.05143855e-01\n  4.93500256e-02  1.57999068e-01  2.76613872e-02  2.10313182e-02\n  4.97555403e-02 -1.82051234e-01 -1.04584881e-01  1.33366435e-01\n -1.30282499e-01  1.27489865e-02  2.67860058e-02 -1.76540329e-02\n -1.85603899e-01  8.44161887e-02  1.44930041e-01 -4.04590466e-02\n -2.72546596e-02  9.65384747e-02  6.79367536e-02  6.19401969e-02\n  1.62215559e-02 -1.73466198e-01 -1.07426492e-02  1.98370560e-01\n  2.64810771e-04  2.41555972e-02  5.94173047e-02 -7.89739424e-02\n  1.14716858e-01 -1.41318770e-01  3.78222366e-02 -2.44036141e-02\n -1.63164185e-01  1.05638171e-01 -1.97889713e-01  9.83388481e-03\n  6.78981617e-03 -1.92814584e-02 -1.22666006e-01  6.08855038e-02\n  1.12958382e-01 -9.18278755e-02  8.35967955e-02  6.08627714e-02\n -6.61944506e-02 -1.46063321e-01 -8.98409359e-03 -4.24843339e-02\n -1.85035248e-01 -7.29081393e-02  1.48409111e-01 -1.21370499e-01\n  6.90850394e-03  1.23923035e-02 -1.75264127e-01 -9.46545143e-02\n -8.88530943e-02 -8.68237288e-03  6.89257820e-02  1.60504123e-01\n -9.65012050e-02 -2.40441278e-02 -7.01500740e-02 -1.66911908e-01\n  6.61748936e-02 -3.71682245e-02 -4.55569319e-02  1.93716632e-01\n  1.15691529e-02  1.99935696e-02  1.04858047e-01  3.93880976e-02\n -1.27484798e-01  9.99868114e-02  1.53559945e-01  5.45264976e-02\n  8.51558583e-02 -6.93940856e-02 -4.95620924e-04 -1.41421356e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-2fde729f0bd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_kmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_kmeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'viridis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    885\u001b[0m         \"\"\"\n\u001b[0;32m    886\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 887\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36m_check_fit_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_fit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;34m\"\"\"Verify that the number of samples given is larger than k\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             raise ValueError(\"n_samples=%d should be >= n_clusters=%d\" % (\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 1.41421356e-01 -1.36412301e-02 -2.00000000e-01 -1.58776308e-01\n -1.36569418e-01  2.43605566e-02  1.47006507e-02 -1.99923846e-01\n -4.78910351e-04 -1.97368991e-03 -2.31804253e-03 -5.28971955e-02\n -4.40790235e-02  1.99997735e-01 -3.80814592e-02 -1.99947605e-01\n -4.54748820e-03  4.01751188e-03 -1.90588781e-03 -3.52782876e-03\n -1.13976888e-02  1.99827749e-01 -2.83563319e-02  2.29792366e-02\n  2.88672797e-02 -1.97561759e-01 -2.43947759e-04  1.49705631e-04\n  4.46236779e-04 -1.99999778e-01  3.90379861e-03  5.32897732e-03\n  1.99997243e-01 -1.91054853e-02 -1.99943499e-01 -5.18518716e-05\n  4.63526961e-03 -4.05452011e-04 -4.01866251e-03  1.99995116e-01\n -3.10399569e-03  9.21239120e-04  7.73411042e-04  1.99999446e-01\n  1.33712224e-04  2.16675638e-03  2.33762605e-04 -4.80011838e-02\n  1.99734852e-01  2.23692713e-02 -1.23602796e-03 -8.17343794e-04\n -1.18230723e-03 -1.99861054e-01  1.99793167e-01  9.07858851e-03\n  4.61412404e-03  9.82717149e-03  7.85226356e-04 -1.99990840e-01\n -1.03729657e-02  4.98333741e-04  2.03758763e-03  1.70750877e-03\n  2.33416323e-02 -1.99998834e-01  1.33002327e-03 -4.83449705e-02\n -1.99970572e-01 -5.87422855e-04 -6.59410832e-04  1.54054570e-03\n  2.00630218e-03  1.99999877e-01  1.99999983e-01  3.88489025e-03\n  3.21157157e-03  2.40426388e-03 -3.17035155e-03 -1.99611800e-01\n -1.61993217e-03  1.39468166e-02 -2.52454164e-04  1.19369082e-03\n  1.26370101e-03 -1.99998129e-01 -1.88915211e-03  2.00000000e-01\n -5.73729189e-04 -2.74956266e-04  8.30635342e-04 -5.62023297e-03\n -2.00000000e-01 -3.85046271e-03  1.46552560e-03  1.22348547e-02\n -2.00000000e-01 -3.85014150e-05  4.95620924e-04  1.41421356e-01\n  1.41421356e-01 -1.36412301e-02 -8.51558583e-02 -1.29653316e-01\n -1.63061314e-01  8.67795163e-02  1.24599804e-01  1.29560561e-01\n  7.73818608e-02  5.03192358e-03  4.85716991e-02  4.58082681e-02\n  2.72074451e-02 -1.93694831e-01 -7.09894506e-02  4.05723450e-02\n  1.40854294e-01  1.34189042e-01  5.23103366e-02  1.05143855e-01\n  4.93500256e-02  1.57999068e-01  2.76613872e-02  2.10313182e-02\n  4.97555403e-02 -1.82051234e-01 -1.04584881e-01  1.33366435e-01\n -1.30282499e-01  1.27489865e-02  2.67860058e-02 -1.76540329e-02\n -1.85603899e-01  8.44161887e-02  1.44930041e-01 -4.04590466e-02\n -2.72546596e-02  9.65384747e-02  6.79367536e-02  6.19401969e-02\n  1.62215559e-02 -1.73466198e-01 -1.07426492e-02  1.98370560e-01\n  2.64810771e-04  2.41555972e-02  5.94173047e-02 -7.89739424e-02\n  1.14716858e-01 -1.41318770e-01  3.78222366e-02 -2.44036141e-02\n -1.63164185e-01  1.05638171e-01 -1.97889713e-01  9.83388481e-03\n  6.78981617e-03 -1.92814584e-02 -1.22666006e-01  6.08855038e-02\n  1.12958382e-01 -9.18278755e-02  8.35967955e-02  6.08627714e-02\n -6.61944506e-02 -1.46063321e-01 -8.98409359e-03 -4.24843339e-02\n -1.85035248e-01 -7.29081393e-02  1.48409111e-01 -1.21370499e-01\n  6.90850394e-03  1.23923035e-02 -1.75264127e-01 -9.46545143e-02\n -8.88530943e-02 -8.68237288e-03  6.89257820e-02  1.60504123e-01\n -9.65012050e-02 -2.40441278e-02 -7.01500740e-02 -1.66911908e-01\n  6.61748936e-02 -3.71682245e-02 -4.55569319e-02  1.93716632e-01\n  1.15691529e-02  1.99935696e-02  1.04858047e-01  3.93880976e-02\n -1.27484798e-01  9.99868114e-02  1.53559945e-01  5.45264976e-02\n  8.51558583e-02 -6.93940856e-02 -4.95620924e-04 -1.41421356e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(V)\n",
    "y_kmeans = kmeans.predict(V)\n",
    "plt.scatter(V[:, 0], V[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.41421356e-01, -1.36412301e-02, -2.00000000e-01, -1.58776308e-01,\n",
       "       -1.36569418e-01,  2.43605566e-02,  1.47006507e-02, -1.99923846e-01,\n",
       "       -4.78910351e-04, -1.97368991e-03, -2.31804253e-03, -5.28971955e-02,\n",
       "       -4.40790235e-02,  1.99997735e-01, -3.80814592e-02, -1.99947605e-01,\n",
       "       -4.54748820e-03,  4.01751188e-03, -1.90588781e-03, -3.52782876e-03,\n",
       "       -1.13976888e-02,  1.99827749e-01, -2.83563319e-02,  2.29792366e-02,\n",
       "        2.88672797e-02, -1.97561759e-01, -2.43947759e-04,  1.49705631e-04,\n",
       "        4.46236779e-04, -1.99999778e-01,  3.90379861e-03,  5.32897732e-03,\n",
       "        1.99997243e-01, -1.91054853e-02, -1.99943499e-01, -5.18518716e-05,\n",
       "        4.63526961e-03, -4.05452011e-04, -4.01866251e-03,  1.99995116e-01,\n",
       "       -3.10399569e-03,  9.21239120e-04,  7.73411042e-04,  1.99999446e-01,\n",
       "        1.33712224e-04,  2.16675638e-03,  2.33762605e-04, -4.80011838e-02,\n",
       "        1.99734852e-01,  2.23692713e-02, -1.23602796e-03, -8.17343794e-04,\n",
       "       -1.18230723e-03, -1.99861054e-01,  1.99793167e-01,  9.07858851e-03,\n",
       "        4.61412404e-03,  9.82717149e-03,  7.85226356e-04, -1.99990840e-01,\n",
       "       -1.03729657e-02,  4.98333741e-04,  2.03758763e-03,  1.70750877e-03,\n",
       "        2.33416323e-02, -1.99998834e-01,  1.33002327e-03, -4.83449705e-02,\n",
       "       -1.99970572e-01, -5.87422855e-04, -6.59410832e-04,  1.54054570e-03,\n",
       "        2.00630218e-03,  1.99999877e-01,  1.99999983e-01,  3.88489025e-03,\n",
       "        3.21157157e-03,  2.40426388e-03, -3.17035155e-03, -1.99611800e-01,\n",
       "       -1.61993217e-03,  1.39468166e-02, -2.52454164e-04,  1.19369082e-03,\n",
       "        1.26370101e-03, -1.99998129e-01, -1.88915211e-03,  2.00000000e-01,\n",
       "       -5.73729189e-04, -2.74956266e-04,  8.30635342e-04, -5.62023297e-03,\n",
       "       -2.00000000e-01, -3.85046271e-03,  1.46552560e-03,  1.22348547e-02,\n",
       "       -2.00000000e-01, -3.85014150e-05,  4.95620924e-04,  1.41421356e-01,\n",
       "        1.41421356e-01, -1.36412301e-02, -8.51558583e-02, -1.29653316e-01,\n",
       "       -1.63061314e-01,  8.67795163e-02,  1.24599804e-01,  1.29560561e-01,\n",
       "        7.73818608e-02,  5.03192358e-03,  4.85716991e-02,  4.58082681e-02,\n",
       "        2.72074451e-02, -1.93694831e-01, -7.09894506e-02,  4.05723450e-02,\n",
       "        1.40854294e-01,  1.34189042e-01,  5.23103366e-02,  1.05143855e-01,\n",
       "        4.93500256e-02,  1.57999068e-01,  2.76613872e-02,  2.10313182e-02,\n",
       "        4.97555403e-02, -1.82051234e-01, -1.04584881e-01,  1.33366435e-01,\n",
       "       -1.30282499e-01,  1.27489865e-02,  2.67860058e-02, -1.76540329e-02,\n",
       "       -1.85603899e-01,  8.44161887e-02,  1.44930041e-01, -4.04590466e-02,\n",
       "       -2.72546596e-02,  9.65384747e-02,  6.79367536e-02,  6.19401969e-02,\n",
       "        1.62215559e-02, -1.73466198e-01, -1.07426492e-02,  1.98370560e-01,\n",
       "        2.64810771e-04,  2.41555972e-02,  5.94173047e-02, -7.89739424e-02,\n",
       "        1.14716858e-01, -1.41318770e-01,  3.78222366e-02, -2.44036141e-02,\n",
       "       -1.63164185e-01,  1.05638171e-01, -1.97889713e-01,  9.83388481e-03,\n",
       "        6.78981617e-03, -1.92814584e-02, -1.22666006e-01,  6.08855038e-02,\n",
       "        1.12958382e-01, -9.18278755e-02,  8.35967955e-02,  6.08627714e-02,\n",
       "       -6.61944506e-02, -1.46063321e-01, -8.98409359e-03, -4.24843339e-02,\n",
       "       -1.85035248e-01, -7.29081393e-02,  1.48409111e-01, -1.21370499e-01,\n",
       "        6.90850394e-03,  1.23923035e-02, -1.75264127e-01, -9.46545143e-02,\n",
       "       -8.88530943e-02, -8.68237288e-03,  6.89257820e-02,  1.60504123e-01,\n",
       "       -9.65012050e-02, -2.40441278e-02, -7.01500740e-02, -1.66911908e-01,\n",
       "        6.61748936e-02, -3.71682245e-02, -4.55569319e-02,  1.93716632e-01,\n",
       "        1.15691529e-02,  1.99935696e-02,  1.04858047e-01,  3.93880976e-02,\n",
       "       -1.27484798e-01,  9.99868114e-02,  1.53559945e-01,  5.45264976e-02,\n",
       "        8.51558583e-02, -6.93940856e-02, -4.95620924e-04, -1.41421356e-01])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((vectors[0], vectors[1]), axis = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
